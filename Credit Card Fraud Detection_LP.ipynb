{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab174bc5",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd65dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ddfb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv(\"creditcardfraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1585a051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82450</td>\n",
       "      <td>1.314539</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>-0.666593</td>\n",
       "      <td>0.716564</td>\n",
       "      <td>0.301978</td>\n",
       "      <td>-1.125467</td>\n",
       "      <td>0.388881</td>\n",
       "      <td>-0.288390</td>\n",
       "      <td>-0.132137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170307</td>\n",
       "      <td>-0.429655</td>\n",
       "      <td>-0.141341</td>\n",
       "      <td>-0.200195</td>\n",
       "      <td>0.639491</td>\n",
       "      <td>0.399476</td>\n",
       "      <td>-0.034321</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50554</td>\n",
       "      <td>-0.798672</td>\n",
       "      <td>1.185093</td>\n",
       "      <td>0.904547</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>0.219041</td>\n",
       "      <td>-0.319295</td>\n",
       "      <td>0.495236</td>\n",
       "      <td>0.139269</td>\n",
       "      <td>-0.760214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202287</td>\n",
       "      <td>0.578699</td>\n",
       "      <td>-0.092245</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>-0.246466</td>\n",
       "      <td>-0.380057</td>\n",
       "      <td>-0.396030</td>\n",
       "      <td>-0.112901</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55125</td>\n",
       "      <td>-0.391128</td>\n",
       "      <td>-0.245540</td>\n",
       "      <td>1.122074</td>\n",
       "      <td>-1.308725</td>\n",
       "      <td>-0.639891</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>-0.701304</td>\n",
       "      <td>-0.027315</td>\n",
       "      <td>-2.628854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133485</td>\n",
       "      <td>0.117403</td>\n",
       "      <td>-0.191748</td>\n",
       "      <td>-0.488642</td>\n",
       "      <td>-0.309774</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.163716</td>\n",
       "      <td>0.239582</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116572</td>\n",
       "      <td>-0.060302</td>\n",
       "      <td>1.065093</td>\n",
       "      <td>-0.987421</td>\n",
       "      <td>-0.029567</td>\n",
       "      <td>0.176376</td>\n",
       "      <td>-1.348539</td>\n",
       "      <td>0.775644</td>\n",
       "      <td>0.134843</td>\n",
       "      <td>-0.149734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355576</td>\n",
       "      <td>0.907570</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>-0.126269</td>\n",
       "      <td>-0.339923</td>\n",
       "      <td>-0.150285</td>\n",
       "      <td>-0.023634</td>\n",
       "      <td>0.042330</td>\n",
       "      <td>57.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90434</td>\n",
       "      <td>1.848433</td>\n",
       "      <td>0.373364</td>\n",
       "      <td>0.269272</td>\n",
       "      <td>3.866438</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.970447</td>\n",
       "      <td>-0.721945</td>\n",
       "      <td>0.235983</td>\n",
       "      <td>0.683491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103563</td>\n",
       "      <td>0.620954</td>\n",
       "      <td>0.197077</td>\n",
       "      <td>0.692392</td>\n",
       "      <td>-0.206530</td>\n",
       "      <td>-0.021328</td>\n",
       "      <td>-0.019823</td>\n",
       "      <td>-0.042682</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   82450  1.314539  0.590643 -0.666593  0.716564  0.301978 -1.125467   \n",
       "1   50554 -0.798672  1.185093  0.904547  0.694584  0.219041 -0.319295   \n",
       "2   55125 -0.391128 -0.245540  1.122074 -1.308725 -0.639891  0.008678   \n",
       "3  116572 -0.060302  1.065093 -0.987421 -0.029567  0.176376 -1.348539   \n",
       "4   90434  1.848433  0.373364  0.269272  3.866438  0.088062  0.970447   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.388881 -0.288390 -0.132137  ... -0.170307 -0.429655 -0.141341 -0.200195   \n",
       "1  0.495236  0.139269 -0.760214  ...  0.202287  0.578699 -0.092245  0.013723   \n",
       "2 -0.701304 -0.027315 -2.628854  ... -0.133485  0.117403 -0.191748 -0.488642   \n",
       "3  0.775644  0.134843 -0.149734  ...  0.355576  0.907570 -0.018454 -0.126269   \n",
       "4 -0.721945  0.235983  0.683491  ...  0.103563  0.620954  0.197077  0.692392   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.639491  0.399476 -0.034321  0.031692    0.76      0  \n",
       "1 -0.246466 -0.380057 -0.396030 -0.112901    4.18      0  \n",
       "2 -0.309774  0.008100  0.163716  0.239582   15.00      0  \n",
       "3 -0.339923 -0.150285 -0.023634  0.042330   57.00      0  \n",
       "4 -0.206530 -0.021328 -0.019823 -0.042682    0.00      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d43047e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94790b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "data.drop(\"Time\", axis=1, inplace=True)\n",
    "scaler = StandardScaler()\n",
    "data[\"Amount\"] = scaler.fit_transform(data[\"Amount\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6cb568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split data into training and test sets\n",
    "X = data.drop(\"Class\", axis=1)\n",
    "y = data[\"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e7904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Logistic Regression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab97b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "\n",
      "Confusion Matrix:\n",
      "[[59  3]\n",
      " [ 4 54]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94        62\n",
      "           1       0.95      0.93      0.94        58\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.94      0.94      0.94       120\n",
      "weighted avg       0.94      0.94      0.94       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Logistic Regression\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_logistic))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f1118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: SVM Model\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e826e8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Performance:\n",
      "Confusion Matrix:\n",
      "[[62  0]\n",
      " [ 6 52]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        62\n",
      "           1       1.00      0.90      0.95        58\n",
      "\n",
      "    accuracy                           0.95       120\n",
      "   macro avg       0.96      0.95      0.95       120\n",
      "weighted avg       0.95      0.95      0.95       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SVM Model\n",
    "print(\"\\nSVM Performance:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc7808d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.677 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.719 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.677 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.896 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.948 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.896 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.865 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.906 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.885 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.896 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.906 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.927 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.969 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.948 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.1, 0.01, 0.001],\n",
       "                         'kernel': ['rbf']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Hyperparameter Tuning\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deec7ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Best parameters\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a2444f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train Models with Optimal Hyperparameters\n",
    "best_svm_model = grid_search.best_estimator_\n",
    "best_svm_model.fit(X_train, y_train)\n",
    "y_pred_best_svm = best_svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7be22f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best SVM Performance:\n",
      "Confusion Matrix:\n",
      "[[62  0]\n",
      " [ 5 53]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        62\n",
      "           1       1.00      0.91      0.95        58\n",
      "\n",
      "    accuracy                           0.96       120\n",
      "   macro avg       0.96      0.96      0.96       120\n",
      "weighted avg       0.96      0.96      0.96       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Best SVM Model\n",
    "print(\"\\nBest SVM Performance:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best_svm))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_best_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "953f80d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reset index of y_test\n",
    "y_test_reset_index = y_test.reset_index(drop=True)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(y_test_reset_index)\n",
    "plt.title('Actual')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(y_pred_best_svm)\n",
    "plt.title('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bcac3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Summary Report: Credit Card Fraud Detection\n",
    "\n",
    "This analysis aimed to predict fraudulent credit card transactions using logistic regression and support vector machine (SVM) models. The \"creditcardfraud.csv\" dataset was utilized, containing anonymized transaction features and a binary target variable indicating fraud.\n",
    "\n",
    "After preprocessing, including dropping the \"Time\" column and scaling the \"Amount\" column, the data was split into training and test sets.\n",
    "\n",
    "A logistic regression model and an SVM model were trained on the training set using default hyperparameters. The performance of both models was evaluated on the test set using confusion matrices and classification reports.\n",
    "\n",
    "Further, hyperparameters were tuned using grid search cross-validation to optimize model performance. The best SVM model achieved superior results compared to logistic regression, with higher accuracy and precision in detecting fraudulent transactions.\n",
    "\n",
    "In conclusion, the SVM model outperformed logistic regression in credit card fraud detection. These findings highlight the effectiveness of SVMs in handling complex classification tasks, particularly in scenarios with imbalanced data and non-linear relationships."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
